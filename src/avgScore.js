// Average score of each language in a correct detection, done with an extended version of big-test benchmark.
// TODO include this inside each ngrams database, although differences are small between database sizes
export const avgScore = {
    'am': 0.832,
    'ar': 0.845,
    'az': 0.804,
    'be': 0.841,
    'bg': 0.838,
    'bn': 0.876,
    'ca': 0.762,
    'cs': 0.759,
    'da': 0.77,
    'de': 0.777,
    'el': 0.801,
    'en': 0.777,
    'es': 0.771,
    'et': 0.779,
    'eu': 0.746,
    'fa': 0.831,
    'fi': 0.784,
    'fr': 0.783,
    'gu': 0.872,
    'he': 0.803,
    'hi': 0.883,
    'hr': 0.77,
    'hu': 0.752,
    'hy': 0.802,
    'is': 0.788,
    'it': 0.784,
    'ja': 0.796,
    'ka': 0.893,
    'kn': 0.875,
    'ko': 0.764,
    'ku': 0.853,
    'lo': 0.873,
    'lt': 0.777,
    'lv': 0.789,
    'ml': 0.874,
    'mr': 0.884,
    'ms': 0.774,
    'nl': 0.77,
    'no': 0.75,
    'or': 0.872,
    'pa': 0.873,
    'pl': 0.768,
    'pt': 0.78,
    'ro': 0.771,
    'ru': 0.833,
    'sk': 0.763,
    'sl': 0.771,
    'sq': 0.789,
    'sr': 0.838,
    'sv': 0.767,
    'ta': 0.882,
    'te': 0.878,
    'th': 0.864,
    'tl': 0.777,
    'tr': 0.783,
    'uk': 0.836,
    'ur': 0.827,
    'vi': 0.848,
    'yo': 0.752,
    'zh': 0.752
}

/* Deprecated for now: Some languages score higher with the same amount of text, this multiplier evens it out for
 *  multi-language strings
 * scoreNormalizer = [0.7, 1, 1, 1, 1, 0.6, 0.98, 1, 1, 1, 0.9, 1, 1, 1, 1, 1, 1, 1, 0.6, 1, 0.7, 1, 1, 0.9, 1, 1, 0.8,
 * 0.6, 0.6, 1, 1, 0.5, 1, 1, 0.6, 0.7, 1, 0.95, 1, 0.6, 0.6, 1, 1, 1, 1, 1, 1, 0.9, 1, 1, 0.6, 0.6, 0.7, 0.9, 1, 1, 1,
 * 0.8, 1, 1.7]
 */
